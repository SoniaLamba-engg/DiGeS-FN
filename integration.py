# -*- coding: utf-8 -*-
"""Integration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13dqPcBdEPgtyWu6Jm4j5Ra0ZFEmgyDil
"""

from google.colab import drive
# Mount Google Drive
drive.mount('/content/drive')

import math

def calculate_square_root(value):
    """
    Calculates the square root of the input value.

    Parameters:
    - value (float): The input value for which the square root will be calculated.

    Returns:
    - float: The square root of the input value.
    """
    return math.sqrt(value)

# Example usage:
input_value = 0.0010374
result = calculate_square_root(input_value)
print(f"The square root of {input_value} is: {result}")

import numpy as np

# Define the matrices
matrix1 = np.array([[1, 5, 8],
                    [4, 2, 7],
                    [7, 8, 3]])

matrix2 = np.array([[5, 4, 7],
                    [4, 7, 6],
                    [3, 1, 2]])

# Perform element-wise multiplication
result_matrix = np.multiply(matrix1, matrix2)

# Take the square root of each multiplied value
result_matrix_sqrt = np.sqrt(result_matrix)

print(result_matrix_sqrt)

import pandas as pd
import numpy as np

# Create DataFrames for Matrix 1 and Matrix 2
data1 = {'DOID:1': [1, 4, 7], 'DOID:2': [5, 2, 8], 'DOID:3': [8, 7, 3]}
matrix1 = pd.DataFrame(data1, index=['DOID:1', 'DOID:2', 'DOID:3'])

data2 = {'DOID:1': [5, 4, 3], 'DOID:2': [4, 7, 1], 'DOID:3': [7, 6, 2]}
matrix2 = pd.DataFrame(data2, index=['DOID:1', 'DOID:2', 'DOID:3'])

# Perform element-wise multiplication
result_matrix = matrix1 * matrix2

# Take the square root of each multiplied value
result_matrix_sqrt = result_matrix.applymap(np.sqrt)

# Display the result
print(result_matrix_sqrt)

import pandas as pd
import numpy as np

# Load the first Excel file into a DataFrame and set 'DOID' as the index
file_path1 = '/content/drive/MyDrive/Integration/OS.xlsx'
Overlap_Similarity = pd.read_excel(file_path1).set_index('DOID')

# Load the second Excel file into a DataFrame and set 'DOID' as the index
file_path2 = '/content/drive/MyDrive/Integration/JS.xlsx'
Jaccard_Similarity = pd.read_excel(file_path2).set_index('DOID')

# Perform element-wise multiplication excluding the index column
result = np.sqrt(Overlap_Similarity.values * Jaccard_Similarity.values)

# Create a new DataFrame with the same index and columns
result_df = pd.DataFrame(result, index=Overlap_Similarity.index, columns=Overlap_Similarity.columns)

# Print the result
print(result_df)

import pandas as pd
import numpy as np

# Load the first Excel file into a DataFrame and set 'DOID' as the index
file_path1 = '/content/drive/MyDrive/Integration/OS.xlsx'
Overlap_Similarity = pd.read_excel(file_path1).set_index('DOID')
#print(Overlap_Similarity)

file_path2 = '/content/drive/MyDrive/Integration/JS.xlsx'
Jaccard_Similarity = pd.read_excel(file_path2).set_index('DOID')
#print(Jaccard_Similarity)

# Load the second Excel file into a DataFrame and set 'DOID' as the index
file_path3 = '/content/drive/MyDrive/Integration/SS.xlsx'
Sorensen_Similarity = pd.read_excel(file_path3).set_index('DOID')
#print(Sorensen_Similarity)

# Load the second Excel file into a DataFrame and set 'DOID' as the index
file_path4 = '/content/drive/MyDrive/Integration/PCM.xlsx'
PCM_Similarity = pd.read_excel(file_path4).set_index('DOID')
#print(PCM_Similarity)

# Load the second Excel file into a DataFrame and set 'DOID' as the index
file_path5 = '/content/drive/MyDrive/Integration/CSM.xlsx'
CSM_Similarity = pd.read_excel(file_path5).set_index('DOID')
#print(CSM_Similarity)

# Load the second Excel file into a DataFrame and set 'DOID' as the index
file_path6 = '/content/drive/MyDrive/Integration/resnik_similarity_matrix - Copy.xlsx'
Resnik_Similarity = pd.read_excel(file_path6).set_index('DOID')
#print(Resnik_Similarity)

# Load the second Excel file into a DataFrame and set 'DOID' as the index
file_path7 = '/content/drive/MyDrive/Integration/lins_similarity_matrix - Copy.xlsx'
Lins_Similarity = pd.read_excel(file_path7).set_index('DOID')
print(Lins_Similarity)

# Load the second Excel file into a DataFrame and set 'DOID' as the index
file_path8 = '/content/drive/MyDrive/Integration/semfunsim_matrix_final - Copy.xlsx'
Semfunsim_Similarity = pd.read_excel(file_path8).set_index('DOID')
#print(Semfunsim_Similarity)

file_path9 = '/content/drive/MyDrive/Integration/true positives.xlsx'
actual_df = pd.read_excel(file_path9).set_index('DOID')
#print(actual_df)

"""Pearson (Network) * Semfunsim (Semantic)"""

# Perform element-wise multiplication
result_matrix = PCM_Similarity*Semfunsim_Similarity

# Convert the result back to a DataFrame with the same index and columns
normalized_df = pd.DataFrame(result_matrix, index=PCM_Similarity.index, columns=PCM_Similarity.columns)

# Save the result to a new Excel file
#result_file_path = '/content/Result.xlsx'
#result_df.to_excel(result_file_path)

# Print the result DataFrame
print(normalized_df)

import pandas as pd
import io

# Assuming similarity_matrix_semfunsim is already loaded

# Min-Max normalization function
def min_max_normalize(matrix):
    matrix_array = matrix.values.astype(float)
    min_val = matrix_array.min()
    print(min_val)
    max_val = matrix_array.max()
    print(max_val)
    normalized_matrix = (matrix_array - min_val) / (max_val - min_val)
    return normalized_matrix

# Normalize the similarity matrix
normalized_similarity_matrix = min_max_normalize(normalized_df)

# Create a DataFrame for the normalized matrix
predicted_df = pd.DataFrame(normalized_similarity_matrix, columns=normalized_df.columns, index=normalized_df.index)

# Export the normalized matrix to an Excel file
#normalized_df.to_excel("normalized_matrix_jaccard.xlsx")

# Display the normalized matrix DataFrame
#print("Normalized Similarity Matrix:")
#print(predicted_df)

import pandas as pd
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Assuming you have actual_df and predicted_df dataframes

# Combine the actual and predicted values for each pair of diseases
actual_values = actual_df.values.flatten()
predicted_values = predicted_df_1.values.flatten()

# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(actual_values, predicted_values)

# Compute the Area Under the Curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Integration PCM (Network) & SemFunSim (Semantic) Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

"""CSM (Network) * SemFunSim (Semantic)"""

# Perform element-wise multiplication
result_matrix_11 = np.multiply(CSM_Similarity, Semfunsim_Similarity)

# Convert the result back to a DataFrame with the same index and columns
normalized_df_11 = pd.DataFrame(result_matrix_11, index=CSM_Similarity.index, columns=CSM_Similarity.columns)

import pandas as pd
import io

# Assuming similarity_matrix_semfunsim is already loaded

# Min-Max normalization function
def min_max_normalize(matrix):
    matrix_array = matrix.values.astype(float)
    min_val = matrix_array.min()
    print(min_val)
    max_val = matrix_array.max()
    print(max_val)
    normalized_matrix = (matrix_array - min_val) / (max_val - min_val)
    return normalized_matrix

# Normalize the similarity matrix
normalized_similarity_matrix_11 = min_max_normalize(normalized_df_11)

# Create a DataFrame for the normalized matrix
predicted_df_11 = pd.DataFrame(normalized_similarity_matrix_11, columns=normalized_df_11.columns, index=normalized_df_11.index)

import pandas as pd
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Assuming you have actual_df and predicted_df dataframes

# Combine the actual and predicted values for each pair of diseases
actual_values = actual_df.values.flatten()
predicted_values = predicted_df_11.values.flatten()

# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(actual_values, predicted_values)

# Compute the Area Under the Curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Integration CSM (Network) & SemFunSim (Semantic) Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

"""CSM (Network) * Resnik (Semantic)"""

# Perform element-wise multiplication
result_matrix_111 = np.multiply(CSM_Similarity, Resnik_Similarity)

# Convert the result back to a DataFrame with the same index and columns
normalized_df_111 = pd.DataFrame(result_matrix_111, index=CSM_Similarity.index, columns=CSM_Similarity.columns)

import pandas as pd
import io

# Assuming similarity_matrix_semfunsim is already loaded

# Min-Max normalization function
def min_max_normalize(matrix):
    matrix_array = matrix.values.astype(float)
    min_val = matrix_array.min()
    print(min_val)
    max_val = matrix_array.max()
    print(max_val)
    normalized_matrix = (matrix_array - min_val) / (max_val - min_val)
    return normalized_matrix

# Normalize the similarity matrix
normalized_similarity_matrix_111 = min_max_normalize(normalized_df_111)

# Create a DataFrame for the normalized matrix
predicted_df_111 = pd.DataFrame(normalized_similarity_matrix_111, columns=normalized_df_111.columns, index=normalized_df_111.index)

import pandas as pd
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Assuming you have actual_df and predicted_df dataframes

# Combine the actual and predicted values for each pair of diseases
actual_values = actual_df.values.flatten()
predicted_values = predicted_df_111.values.flatten()

# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(actual_values, predicted_values)

# Compute the Area Under the Curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Integration CSM (Network) & Resnik (Semantic) Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

"""Resnik (Semantic) * PCM (Network)"""

# Perform element-wise multiplication
result_matrix_1111 = np.multiply(PCM_Similarity, Resnik_Similarity)

# Convert the result back to a DataFrame with the same index and columns
normalized_df_1111 = pd.DataFrame(result_matrix_1111, index=PCM_Similarity.index, columns=PCM_Similarity.columns)

import pandas as pd
import io

# Assuming similarity_matrix_semfunsim is already loaded

# Min-Max normalization function
def min_max_normalize(matrix):
    matrix_array = matrix.values.astype(float)
    min_val = matrix_array.min()
    print(min_val)
    max_val = matrix_array.max()
    print(max_val)
    normalized_matrix = (matrix_array - min_val) / (max_val - min_val)
    return normalized_matrix

# Normalize the similarity matrix
normalized_similarity_matrix_1111 = min_max_normalize(normalized_df_1111)

# Create a DataFrame for the normalized matrix
predicted_df_1111 = pd.DataFrame(normalized_similarity_matrix_1111, columns=normalized_df_1111.columns, index=normalized_df_1111.index)

import pandas as pd
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Assuming you have actual_df and predicted_df dataframes

# Combine the actual and predicted values for each pair of diseases
actual_values = actual_df.values.flatten()
predicted_values = predicted_df_1111.values.flatten()

# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(actual_values, predicted_values)

# Compute the Area Under the Curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Integration PCM (Network) & Resnik (Semantic) Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()



import pandas as pd
file_path = '/content/CSM.xlsx'
CSM_Similarity = (pd.read_excel(file_path)).set_index('DOID')
print(CSM_Similarity)

import pandas as pd
file_path = '/content/resnik_similarity_matrix - Copy.xlsx'
Resnik_Similarity = (pd.read_excel(file_path)).set_index('DOID')
print(Resnik_Similarity)

import pandas as pd
file_path = '/content/lins_similarity_matrix.xlsx'
Lins_Similarity = (pd.read_excel(file_path)).set_index('DOID')
#print(Lins_Similarity)

import pandas as pd
file_path = '/content/semfunsim_matrix_final.xlsx'
Semfunsim_Similarity = (pd.read_excel(file_path)).set_index('DOID')
#print(Semfunsim_Similarity)

import pandas as pd
file_path = '/content/drive/MyDrive/Integration/true positives.xlsx'
True_Similarity = (pd.read_excel(file_path)).set_index('DOID')
print(True_Similarity)

"""Resnik (Semantic) * Cosine (Network)"""

import pandas as pd

# Read matrices from Excel files and set 'DOID' as the index
file_path_resnik = '/content/resnik_similarity_matrix - Copy.xlsx'
file_path_csm = '/content/CSM.xlsx'

Resnik_Similarity = pd.read_excel(file_path_resnik, index_col='DOID')
CSM_Similarity = pd.read_excel(file_path_csm, index_col='DOID')

# Perform element-wise multiplication with proper alignment
result_matrix = Resnik_Similarity.mul(CSM_Similarity, fill_value=1)

# Print the result
print(result_matrix)

import pandas as pd
import numpy as np

# Perform element-wise multiplication
df_D = Sorensen_Similarity * Overlap_Similarity

# Take the square root of the result
df_Resnik_CSM_Sqrt = np.sqrt(df_D)
#print(df_result)

import pandas as pd
import io

# Assuming similarity_matrix_semfunsim is already loaded

# Min-Max normalization function
def min_max_normalize(matrix):
    matrix_array = matrix.values.astype(float)
    min_val = matrix_array.min()
    print(min_val)
    max_val = matrix_array.max()
    print(max_val)
    normalized_matrix = (matrix_array - min_val) / (max_val - min_val)
    return normalized_matrix

# Normalize the similarity matrix
normalized_similarity_matrix = min_max_normalize(df_Resnik_CSM)

# Create a DataFrame for the normalized matrix
normalized_df = pd.DataFrame(normalized_similarity_matrix, columns=df_Resnik_CSM.columns, index=df_Resnik_CSM.index)

# Export the normalized matrix to an Excel file
#normalized_df.to_excel("normalized_matrix_jaccard.xlsx")

# Display the normalized matrix DataFrame
#print("Normalized Similarity Matrix:")
#print(normalized_df)





"""import pandas as pd
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Assuming you have actual_df and predicted_df dataframes

# Combine the actual and predicted values for each pair of diseases
actual_values = actual_df.values.flatten()
predicted_values = predicted_df.values.flatten()

# Compute the ROC curve
fpr, tpr, thresholds = roc_curve(actual_values, predicted_values)

# Compute the Area Under the Curve (AUC)
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Jaccard Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()
"""