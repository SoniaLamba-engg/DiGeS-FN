# -*- coding: utf-8 -*-
"""Final DO DAG for Semantic Similarity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10G3lhz_X4nLeMq2zJdALh7nU1zTDMk5j
"""

import networkx as nx
import matplotlib.pyplot as plt

def create_disease_ontology_dag():
    # Create a new directed graph
    graph = nx.DiGraph()

    # Read the disease ontology dataset
    with open('HumanDO.txt', 'r') as file:
        lines = file.readlines()

    term_id = None

    # Process each line in the dataset
    for line in lines:
        line = line.strip()

        if line.startswith('[Term]'):
            if term_id:
                # Add the term to the graph
                graph.add_node(term_id, name=name)

            # Reset the variables for the new term
            term_id = None
            name = None
        elif line.startswith('id:'):
            term_id = line.split(': ')[1]
        elif line.startswith('name:'):
            name = line.split(': ')[1]
        elif line.startswith('is_a:'):
            parent_id = line.split(': ')[1].split(' ! ')[0]
            # Add an edge to represent the "is_a" relationship
            graph.add_edge(term_id, parent_id)

    # Add the last term to the graph
    if term_id:
        graph.add_node(term_id, name=name)

    return graph

# Create the disease ontology DAG
disease_ontology_dag = create_disease_ontology_dag()

# Visualize the DAG
pos = nx.spring_layout(disease_ontology_dag)
nx.draw_networkx(disease_ontology_dag, pos, with_labels=True, node_size=1000, node_color='lightblue',
                 font_size=10, font_weight='bold', edge_color='gray')
plt.axis('off')
plt.show()

# Get the number of nodes and edges
num_nodes = disease_ontology_dag.number_of_nodes()
num_edges = disease_ontology_dag.number_of_edges()

print("Number of nodes:", num_nodes)
print("Number of edges:", num_edges)

def count_disease_ids(dataset_path):
    disease_ids = set()

    with open(dataset_path, 'r') as file:
        lines = file.readlines()

    for line in lines:
        line = line.strip()
        if line.startswith('[Term]'):
            term_id = None
        elif line.startswith('id: DOID:'):
            term_id = line.split(' ')[1]
            disease_ids.add(term_id)

    return len(disease_ids)

# Path to the Disease Ontology dataset (8.0 version)
dataset_path = 'HumanDO.txt'

# Count the number of disease IDs
num_disease_ids = count_disease_ids(dataset_path)

print(f"Number of disease IDs in Disease Ontology (8.0 version): {num_disease_ids}")

import networkx as nx
import math
import pandas as pd

def calculate_ic(graph):
    # Calculate the total number of terms
    total_terms = graph.number_of_nodes()

    # Calculate the IC for each term
    ic_values = {}
    for term in graph.nodes():
        # Calculate the frequency of occurrence (in-degree) for the term
        frequency = graph.in_degree(term)

        # Skip calculation if frequency is zero
        if frequency == 0:
            ic_values[term] = float('inf')
            continue

        # Calculate the probability of the term
        probability = frequency / total_terms

        # Calculate the IC (-log probability)
        ic_values[term] = -math.log(probability)

    return ic_values

# Create the directed acyclic graph (DAG)
disease_ontology_dag = create_disease_ontology_dag()

# Calculate the IC values for each node
ic_values = calculate_ic(disease_ontology_dag)

# Create a DataFrame from the IC values
ic_df = pd.DataFrame({'Term': ic_values.keys(), 'IC': ic_values.values()})

# Save the DataFrame to an Excel file
ic_df.to_excel('ic_values.xlsx', index=False)

import networkx as nx
import math

def calculate_ic(graph):
    # Calculate the total number of terms
    total_terms = graph.number_of_nodes()

    # Calculate the IC for each term
    ic_values = {}
    for term in graph.nodes():
        # Calculate the frequency of occurrence (in-degree) for the term
        frequency = graph.in_degree(term)

        # Skip calculation if frequency is zero
        if frequency == 0:
            ic_values[term] = float('inf')
            continue

        # Calculate the probability of the term
        probability = frequency / total_terms

        # Calculate the IC (-log probability)
        ic_values[term] = -math.log(probability)

    return ic_values

def find_common_ancestor(graph, term1, term2):
    # Get the IC values for each term
    ic_values = calculate_ic(graph)

    # Find all ancestors of term1 and term2
    ancestors1 = nx.ancestors(graph, term1)
    ancestors2 = nx.ancestors(graph, term2)

    # Find the common ancestors between term1 and term2
    common_ancestors = ancestors1.intersection(ancestors2)

    if len(common_ancestors) == 0:
        return None

    # Calculate the IC values for the common ancestors
    ic_common_ancestors = {term: ic_values[term] for term in common_ancestors}

    # Find the most informative common ancestor
    most_informative_ancestor = max(ic_common_ancestors, key=ic_common_ancestors.get)

    return most_informative_ancestor

# Create the directed acyclic graph (DAG)
disease_ontology_dag = create_disease_ontology_dag()

# Define the disease terms
term1 = 'DOID:2841'
term2 = 'DOID:2355'

# Find the most informative common ancestor
common_ancestor = find_common_ancestor(disease_ontology_dag, term1, term2)

if common_ancestor is None:
    print("No common ancestor found.")
else:
    print(f"Most Informative Common Ancestor: {common_ancestor}")

